{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /nfs/home/scg1143/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Document\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "import faiss\n",
    "from huggingface_hub import login\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.schema import MetadataMode, NodeWithScore, QueryBundle\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "login(os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "   EMBED_DIMENSION =  1024\n",
    "   EMBED_MODEL = \"baconnier/Finance_embedding_large_en-V0.1\"\n",
    "   RERANKER_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "   SIM_TOP_K = 50\n",
    "   RERANKER_TOP_N = 30\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "# Llamaindex global settings for llm and embeddings\n",
    "Settings.llm = None\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=cfg.EMBED_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FinQABench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['convfinqa_queries.jsonl', 'ConvFinQA_qrels.tsv', 'FinanceBench_qrels.tsv', 'FinDER_qrels.tsv', 'TATQA_qrels.tsv', 'finqabench_corpus.jsonl', 'finder_corpus.jsonl', 'tatqa_corpus.jsonl', 'tatqa_queries.jsonl', 'multiheirtt_corpus.jsonl', 'convfinqa_corpus.jsonl', 'finqa_queries.jsonl', 'multiheirtt_queries.jsonl', 'finqa_corpus.jsonl', 'financebench_queries.jsonl', 'FinQA_qrels.tsv', 'FinQABench_qrels.tsv', 'sample_submission_.csv', 'MultiHeirtt_qrels.tsv', 'finder_queries.jsonl', 'financebench_corpus.jsonl', 'finqabench_queries.jsonl']\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path.cwd().parent / 'data'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "finq_bench_corpus_path = data_dir / 'finqabench_corpus.jsonl/corpus.jsonl'\n",
    "finq_bench_query_path = data_dir / 'finqabench_queries.jsonl/queries.jsonl'\n",
    "finq_bench_tsv_path = data_dir / 'FinQABench_qrels.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:FinQ Bench\n",
      "Total Corpus:92\n",
      "Total Queries:100\n"
     ]
    }
   ],
   "source": [
    "finq_bench_corpus = pd.read_json(finq_bench_corpus_path, lines=True)\n",
    "finq_bench_queries = pd.read_json(finq_bench_query_path, lines=True)\n",
    "print(\"Dataset:FinQ Bench\\nTotal Corpus:{}\\nTotal Queries:{}\".format(finq_bench_corpus.shape[0], finq_bench_queries.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(df):\n",
    "    \"\"\"Create Documents with metadata from df\"\"\"\n",
    "    documents = []\n",
    "    for idx,row in df.iterrows():\n",
    "        _ = Document(\n",
    "            text=row['text'], \n",
    "            metadata={'_id' : row['_id'], 'title' : row['title']}\n",
    "            )\n",
    "        documents.append(_)\n",
    "    return documents\n",
    "\n",
    "# TODO: Create Custom Retriever Class after finalizing the experiment\n",
    "# https://docs.llamaindex.ai/en/stable/examples/query_engine/CustomRetrievers/\n",
    "\n",
    "\n",
    "class RetrievalAgent:\n",
    "    def __init__(self, cfg, documents):\n",
    "        self.cfg = cfg \n",
    "        self.documents = documents \n",
    "\n",
    "        self.index , self.reranker = self.initialise_retrieval_components()\n",
    "\n",
    "    def initialise_retrieval_components(self):\n",
    "        # Create FaisVectorStore to store embeddings\n",
    "        fais_index = faiss.IndexFlatL2(self.cfg.EMBED_DIMENSION)\n",
    "        vector_store = FaissVectorStore(faiss_index=fais_index)\n",
    "        print(\"Vector Store Created\")\n",
    "\n",
    "        ## Can experiment with different transformations\n",
    "        base_pipeline = IngestionPipeline(\n",
    "            transformations=[SentenceSplitter(chunk_size=256, chunk_overlap=20)],\n",
    "            vector_store=vector_store,\n",
    "            documents=self.documents\n",
    "        )\n",
    "        nodes = base_pipeline.run()\n",
    "\n",
    "        # Create vector index from base nodes\n",
    "        index = VectorStoreIndex(nodes)\n",
    "        print(\"Vector Index Initialised\")\n",
    "        \n",
    "        # Create Reranker\n",
    "        reranker = SentenceTransformerRerank(\n",
    "                    model=self.cfg.RERANKER_MODEL,\n",
    "                    top_n=self.cfg.RERANKER_TOP_N\n",
    "                )\n",
    "        print(\"Reranker Initialised\")\n",
    "        return index, reranker \n",
    "\n",
    "    def retrieve_nodes(self, query_str, with_reranker=True):\n",
    "        query_bundle = QueryBundle(query_str)\n",
    "        # configure retriever\n",
    "        retriever = VectorIndexRetriever(\n",
    "            index=self.index,\n",
    "            similarity_top_k=self.cfg.SIM_TOP_K\n",
    "        )\n",
    "        retrieved_nodes = retriever.retrieve(query_bundle)\n",
    "\n",
    "        if with_reranker:    \n",
    "            retrieved_nodes = self.reranker.postprocess_nodes(\n",
    "                retrieved_nodes, query_bundle\n",
    "            )\n",
    "\n",
    "        return retrieved_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_nodes(nodes, extract_unique=True):\n",
    "    init_rows = []\n",
    "    for node in nodes:\n",
    "        tmp = {\n",
    "            \"score\" : node.score,\n",
    "            \"text\" : node.text,\n",
    "            \"corpus_id\" : node.metadata['_id']\n",
    "        }\n",
    "        init_rows.append(tmp)\n",
    "    tmp_df = pd.DataFrame(init_rows)\n",
    "\n",
    "    if not extract_unique:\n",
    "        return tmp_df \n",
    "    \n",
    "    final_rows = []\n",
    "    for corpus_id, corpus_df in tmp_df.groupby('corpus_id'):\n",
    "        max_score = corpus_df['score'].max()\n",
    "        text = corpus_df[corpus_df.score == max_score].text.tolist()[0]\n",
    "        final_rows.append({\n",
    "            \"corpus_id\" : corpus_id, \n",
    "            \"text\" : text, \n",
    "            \"score\" : max_score\n",
    "        })\n",
    "    df = pd.DataFrame(final_rows)\n",
    "    df = df.sort_values(by='score', ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Created\n",
      "Vector Index Initialised\n",
      "Reranker Initialised\n"
     ]
    }
   ],
   "source": [
    "# Create FinQ Bench Documents\n",
    "finq_bench_documents = create_documents(finq_bench_corpus)\n",
    "\n",
    "# Initialize Retrieval Agent \n",
    "ret_agent = RetrievalAgent(cfg=cfg, documents=finq_bench_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = finq_bench_queries.iloc[10].text\n",
    "nodes = ret_agent.retrieve_nodes(sample_query)\n",
    "node_df = create_df_from_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id_list = []\n",
    "corpus_id_list = []\n",
    "score_list = []\n",
    "\n",
    "for idx,row in finq_bench_queries.iterrows():\n",
    "    query_id = row['_id']\n",
    "    query_text = row['text']\n",
    "\n",
    "    nodes = ret_agent.retrieve_nodes(query_text)\n",
    "    # Extract top 10 unique corpus_id\n",
    "    node_df = create_df_from_nodes(nodes)[:10]\n",
    "\n",
    "    query_id_list.extend([query_id] * 10)\n",
    "    corpus_id_list.extend(node_df.corpus_id.tolist())\n",
    "    score_list.extend(node_df.score.tolist())\n",
    "\n",
    "\n",
    "final_df = pd.DataFrame({\n",
    "    \"query_id\" : query_id_list, \n",
    "    \"corpus_id\" : corpus_id_list,\n",
    "    \"score\" : score_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa0b1f2</td>\n",
       "      <td>8.651594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa0a52c</td>\n",
       "      <td>4.465078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa0a9e6</td>\n",
       "      <td>4.373746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa18e92</td>\n",
       "      <td>4.332072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa1b854</td>\n",
       "      <td>4.299079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa10314</td>\n",
       "      <td>4.128644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa0a7d4</td>\n",
       "      <td>3.507901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa09b4a</td>\n",
       "      <td>2.562739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa1afee</td>\n",
       "      <td>1.981896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>q4aa0b116</td>\n",
       "      <td>d4aa0a66c</td>\n",
       "      <td>0.916237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa0a52c</td>\n",
       "      <td>8.403464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa0b1f2</td>\n",
       "      <td>7.296615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa0a7d4</td>\n",
       "      <td>5.999946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa0a66c</td>\n",
       "      <td>5.775865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa1afee</td>\n",
       "      <td>4.442026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa0985c</td>\n",
       "      <td>3.749608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa0a9e6</td>\n",
       "      <td>3.505880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa09b4a</td>\n",
       "      <td>2.978142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa124fc</td>\n",
       "      <td>2.839581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>q4aa0a48c</td>\n",
       "      <td>d4aa113f4</td>\n",
       "      <td>1.288238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id  corpus_id     score\n",
       "0   q4aa0b116  d4aa0b1f2  8.651594\n",
       "1   q4aa0b116  d4aa0a52c  4.465078\n",
       "2   q4aa0b116  d4aa0a9e6  4.373746\n",
       "3   q4aa0b116  d4aa18e92  4.332072\n",
       "4   q4aa0b116  d4aa1b854  4.299079\n",
       "5   q4aa0b116  d4aa10314  4.128644\n",
       "6   q4aa0b116  d4aa0a7d4  3.507901\n",
       "7   q4aa0b116  d4aa09b4a  2.562739\n",
       "8   q4aa0b116  d4aa1afee  1.981896\n",
       "9   q4aa0b116  d4aa0a66c  0.916237\n",
       "10  q4aa0a48c  d4aa0a52c  8.403464\n",
       "11  q4aa0a48c  d4aa0b1f2  7.296615\n",
       "12  q4aa0a48c  d4aa0a7d4  5.999946\n",
       "13  q4aa0a48c  d4aa0a66c  5.775865\n",
       "14  q4aa0a48c  d4aa1afee  4.442026\n",
       "15  q4aa0a48c  d4aa0985c  3.749608\n",
       "16  q4aa0a48c  d4aa0a9e6  3.505880\n",
       "17  q4aa0a48c  d4aa09b4a  2.978142\n",
       "18  q4aa0a48c  d4aa124fc  2.839581\n",
       "19  q4aa0a48c  d4aa113f4  1.288238"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.10 ('fin_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24178e9080b9111c74efca0fe0e59b8013241aff9e5d7780cefaf674cfabb6e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
